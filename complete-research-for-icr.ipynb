{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![cover_1](https://raw.githubusercontent.com/AniMilina/ICR---Identifying-Age-Related-Conditions/main/cover_1.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Task: Identifying Health Characteristics Associated with Three Age-Related Conditions\n\n### Input Data\n\n- The competition data includes over fifty anonymous health characteristics associated with three age-related conditions.\n\n### Goal\n\n- The goal of this research is to predict whether a subject has been diagnosed with one of these conditions - making it a binary classification task.\n\n### Evaluation Metric\n\n- The evaluation in this competition is based on balanced log loss, which takes into account the importance of both classes and their predicted probabilities.\n\n### Tasks\n\n1. Exploratory Data Analysis:\n   - Study the data structure and health characteristics' features.\n   - Analyze the distribution of features and the target variable.\n   - Identify outliers and missing values.\n\n2. Data Preprocessing:\n   - Handle outliers and abnormal values.\n   - Fill in missing values or remove corresponding records.\n\n3. Feature Engineering:\n   - Extract information from existing features.\n   - Encode categorical features.\n   - Generate combined features.\n\n4. Modeling:\n   - Choose appropriate machine learning algorithms for classification.\n   - Tune hyperparameters of models.\n   - Evaluate the impact of original and new features on model performance.\n\n5. Model Evaluation:\n   - Measure model training and prediction times.\n   - Calculate additional model metrics.\n\n6. Selecting the Best Model:\n   - Compare models based on quality metrics.\n   - Study the results to decide on the best model.\n\n7. Further Research:\n   - Conduct an in-depth analysis of relationships between characteristics and health conditions.\n\n# Our Data: Dataset Description\n\nThe competition data includes over fifty anonymous health characteristics associated with three age-related conditions. Our goal is to predict whether a subject has been diagnosed with one of these conditions - making it a binary classification problem.\n\nAt the initial stage, the actual test set is hidden. The full test set contains about 400 rows, which will be provided by the client after evaluating the research.\n\n### Files and Field Descriptions\n\n- train.csv: Training dataset.\n  - Id: Unique identifier for each observation.\n  - AB-GL: Fifty-six anonymous health characteristics. All are numerical, except EJ, which is categorical.\n  - Class: Binary target. Value 1 indicates that the subject has been diagnosed with one of the three conditions, and value 0 indicates the absence of a diagnosed condition.\n\n- test.csv: Test dataset. Your goal is to predict the probability of the subject in this dataset belonging to each of the two classes.\n\n- greeks.csv: Additional metadata, available only for the training set.\n  - Alpha: Defines the type of age-related condition, if present.\n  - A: Absence of age-related changes. Corresponds to class 0.\n  - B, D, G: Three age-related conditions. Correspond to class 1.\n  - Beta, Gamma, Delta: Three experimental features.\n  - Epsilon: Data collection date for this question. Note that all data in the test set was collected after the training set.\n\n- sample_submission.csv: Sample submission file in the correct format. Refer to the Evaluation page for more detailed information.","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":" ###  Importing  Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport json\nimport warnings\nimport joblib\nfrom datetime import date, time, datetime\nfrom time import time\nfrom tqdm.notebook import tqdm\nfrom itertools import combinations\n\nimport tensorflow_decision_forests as tfdf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import LinearSegmentedColormap\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\nimport phik\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_selection import mutual_info_classif, mutual_info_regression\nfrom sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_regression\n\nfrom sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector, TransformedTargetRegressor\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, QuantileTransformer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n# from sklearn_extensions.preprocessing import SplineTransformer\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import Pipeline, make_pipeline\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.dummy import DummyRegressor,DummyClassifier\nfrom xgboost import XGBRegressor,XGBClassifier\nfrom sklearn.svm import LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\nfrom lightgbm import LGBMRegressor,LGBMClassifier\nfrom catboost import CatBoostRegressor,CatBoostClassifier\n\nfrom sklearn.metrics import mean_squared_error,log_loss\nfrom sklearn.inspection import permutation_importance\n\nimport optuna\n# from optuna.distributions import FloatDistribution, IntDistribution, CategoricalDistribution","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:33.396741Z","iopub.execute_input":"2023-07-31T09:46:33.398108Z","iopub.status.idle":"2023-07-31T09:46:48.607274Z","shell.execute_reply.started":"2023-07-31T09:46:33.398049Z","shell.execute_reply":"2023-07-31T09:46:48.605937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Constants","metadata":{}},{"cell_type":"code","source":"PATH_LOCAL = 'datasets/'                               # local path to data\nPATH_REMOTE = '/datasets/'                             # remote path to data\n\nCR = '\\n'                                              # carriage return\n\nRANDOM_STATE = RANDOM_SEED = RS = 88                   # random state\nTARGET = 'Class'                                       # target feature\nSCORING = 'neg_log_loss'                               # scoring metric\nVALID_FRAC = 0.2                                       # fraction of validation set\nN_CV = 5                                               # number of cross-validation splits\n\nN_TRIALS = 30                                          # maximum number of trials for Optuna optimization\nTIMEOUT = 1000                                         # maximum execution time for Optuna optimization","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.610237Z","iopub.execute_input":"2023-07-31T09:46:48.610679Z","iopub.status.idle":"2023-07-31T09:46:48.618522Z","shell.execute_reply.started":"2023-07-31T09:46:48.610641Z","shell.execute_reply":"2023-07-31T09:46:48.617097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ESTIMATOR_LIST = [\n    'DummyClassifier',\n    'XGBClassifier',\n    # 'LinearSVC',\n    'RandomForestClassifier',\n    'LGBMClassifier',\n    # 'CatBoostClassifier',\n]","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.620110Z","iopub.execute_input":"2023-07-31T09:46:48.620587Z","iopub.status.idle":"2023-07-31T09:46:48.641407Z","shell.execute_reply.started":"2023-07-31T09:46:48.620548Z","shell.execute_reply":"2023-07-31T09:46:48.639954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"# Function to Get Data Information\n\ndef explore_dataframe(df):\n#     # Shape\n#     shape_info = pd.DataFrame({\"Shape of dataframe\": [f\"Total: {df.shape[0]} rows, {df.shape[1]} columns\"]})\n#     shape_info = shape_info.replace(np.nan, \"-\")\n    \n    # Data Types\n    data_types_info = df.dtypes.to_frame().reset_index().rename(columns={\"index\": \"Data Type\", 0: \"\"})\n    \n    # Missing Values\n    missing_values_info = df.isnull().sum().to_frame().reset_index().rename(columns={\"index\": \"Missing Values\", 0: \"\"})\n    missing_values_info[\"Missing Values\"] = missing_values_info[\"Missing Values\"].fillna(\"-\")\n    \n    # Duplicate Rows\n    duplicate_rows_info = pd.DataFrame({\"Duplicate rows in dataframe\": [f\"Total: {df.duplicated().sum()}\"]})\n    duplicate_rows_info = duplicate_rows_info.replace(np.nan, \"-\")\n    \n     # Unique Values\n    unique_values_info = df.nunique().to_frame().reset_index().rename(columns={\"index\": \"Column\", 0: \"Unique Values\"})\n    \n    # Describe\n    describe_info = df.describe().transpose().reset_index().rename(columns={\"index\": \"Column\"})\n\n    # Concatenate tables\n    info_table = pd.concat([data_types_info, missing_values_info, unique_values_info], axis=1) #shape_info, на время удалила\n    \n    \n    # Display tables\n    display(df.head())\n    display(df.describe())  \n    display(info_table)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.643162Z","iopub.execute_input":"2023-07-31T09:46:48.644030Z","iopub.status.idle":"2023-07-31T09:46:48.657837Z","shell.execute_reply.started":"2023-07-31T09:46:48.643980Z","shell.execute_reply":"2023-07-31T09:46:48.656665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mutual_info(df, target_name, task=None, min_neighbors=1, max_neighbors=7):\n    '''\n    Calculates feature importance using mutual_info\n    df: dataframe with features and target variable\n    target_name: name of the target variable\n    task: choose the task - classification or regression\n    min_neighbors, max_neighbors: range of k for k-neighbors (the final result is averaged)\n    '''\n\n    if max_neighbors < min_neighbors:\n        print(\"Parameter 'max_neighbors' can't be less than parameter 'min_neighbors'.\")\n        return\n\n    X = df.copy()\n    Y = X.pop(target_name)\n\n    df_mutual_info = pd.DataFrame(index=X.columns)\n\n    # Label encoding for categoricals\n    for column in X.select_dtypes(exclude='number'):\n        X[column], _ = X[column].factorize()\n\n    # All discrete features should have integer dtypes\n    for k in range(min_neighbors, max_neighbors+1, 2):\n        if task == 'classification':\n            df_mutual_info[f'k_{k}'] = mutual_info_classif(X, Y, n_neighbors=k, random_state=RS)\n        elif task == 'regression':\n            df_mutual_info[f'k_{k}'] = mutual_info_regression(X, Y, n_neighbors=k, random_state=RS)\n        else:\n            print('Wrong parameter \"task\". Available task=\"classification\" or task=\"regression\".')\n            return\n\n    df_mutual_info['average'] = df_mutual_info.mean(axis=1)\n    df_mutual_info = df_mutual_info.sort_values('average', ascending=False)\n\n    display(df_mutual_info)\n\n    fig, ax = plt.subplots(figsize=(15, df_mutual_info.shape[0]/3), dpi=PLOT_DPI)\n    sns.barplot(x=df_mutual_info.average, y=df_mutual_info.index, palette=['#808080', 'hotpink'], data=df_mutual_info)\n    ax.set_xlabel(f'mutual_info (average across from 1 to {max_neighbors} neighbors)')\n    plt.show()\n    \n    df_mutual_info['average'] = df_mutual_info.mean(axis=1)\n    df_mutual_info = df_mutual_info.sort_values('average', ascending=False)\n    \n    display(df_mutual_info)\n    \n    fig, ax = plt.subplots(figsize=(15, df_mutual_info.shape[0]/3), dpi=PLOT_DPI)\n    sns.barplot(x=df_mutual_info.average, y=df_mutual_info.index, color='steelblue')\n    ax.set_xlabel(f'mutual_info (average across from 1 to {max_neighbors} neighbours)')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.661985Z","iopub.execute_input":"2023-07-31T09:46:48.662939Z","iopub.status.idle":"2023-07-31T09:46:48.680821Z","shell.execute_reply.started":"2023-07-31T09:46:48.662892Z","shell.execute_reply":"2023-07-31T09:46:48.679710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def target_correlation_significance(df, target_name, interval_features):\n    '''\n    df: DataFrame containing features and target variable\n    target_name: name of the target variable\n    interval_features: list of interval features (required for more accurate Phik computation)\n\n    Calculates:\n    - Correlation of features with respect to the target variable\n    - Normalized statistical significance of features\n    - Product of correlation and statistical significance\n    - Harmonic mean of correlation and statistical significance\n\n    Sorts the features based on the harmonic mean.\n    '''\n    \n    # correlation to target\n    df_corr = df.phik_matrix(interval_cols=interval_features)[target_name].to_frame().drop(target_name, axis=0)\n    df_corr.columns = ['correlation']\n    \n    # significance of the correlations\n    df_significance = df.significance_matrix(interval_cols=interval_features, nsim=50)[target_name].to_frame().drop(target_name, axis=0)\n    df_significance = df_significance.assign(significance=lambda x: x[target_name] / x[target_name].max()).drop(target_name, axis=1)\n    \n    # joined\n    df_joined = df_corr.join(df_significance, how='outer')\n    df_joined['product'] = df_joined['correlation'] * df_joined['significance']\n    df_joined['harmonic_mean'] = (2 * df_joined['correlation'] * df_joined['significance']) / (\n                df_joined['correlation'] + df_joined['significance'])\n    df_joined = df_joined.sort_values('harmonic_mean', ascending=False)\n    \n    # display table\n    display(df_joined)\n    \n    # plot\n    fig, ax = plt.subplots(figsize=(15, df_joined.shape[0]/3), dpi=100)\n    sns.barplot(x='harmonic_mean', y=df_joined.index, palette=['#808080', 'hotpink'], data=df_joined)\n    ax.set_xlabel('Harmonic Mean of Target Correlation and Significance')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.682316Z","iopub.execute_input":"2023-07-31T09:46:48.683459Z","iopub.status.idle":"2023-07-31T09:46:48.700407Z","shell.execute_reply.started":"2023-07-31T09:46:48.683419Z","shell.execute_reply":"2023-07-31T09:46:48.698981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_Optuna(study, plot_kind='plot_slice', model_name=''):\n    '''\n    Additional customization of original Optuna plots.\n    For example, for the `plot_slice` plot, the color of points initially depended on the iteration number.\n    Now, all points have the same color and are semi-transparent, making clusters of points more visible.\n\n    study: trained object of OptunaSearchCV class\n    plot_kind: type of Optuna plot\n    model_name: name of the model\n    '''\n    \n    if plot_kind == 'plot_slice':\n        fig = optuna.visualization.plot_slice(study)\n        fig.update_traces(\n            marker_color='lightgrey',\n            marker_size=3,\n            marker_opacity=0.5,\n            marker_line_width=0.5,\n            marker_line_color='black',\n        )\n    \n    elif plot_kind == 'plot_param_importances':\n        fig = optuna.visualization.plot_param_importances(study)\n        \n    elif plot_kind == 'plot_optimization_history':\n        fig = optuna.visualization.plot_optimization_history(study)\n        fig.update_traces(\n            marker_size=5,\n            marker_opacity=0.3,\n            marker_line_width=1,\n            marker_line_color='black',\n        )\n\n    fig.update_layout(\n        title_text=model_name,\n        title_x=0,\n        font_size=10,\n    )    \n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.702519Z","iopub.execute_input":"2023-07-31T09:46:48.703941Z","iopub.status.idle":"2023-07-31T09:46:48.716925Z","shell.execute_reply.started":"2023-07-31T09:46:48.703879Z","shell.execute_reply":"2023-07-31T09:46:48.715347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_feature_importances(chart_title, feature_names, feature_importances):\n    \"\"\"\n    Plots the feature importance chart used by the model.\n\n   chart_title: title of the chart\n   feature_names: names of the features\n   feature_importances: importance of the features\n    \"\"\"\n\n    df = pd.DataFrame({'features': feature_names,\n                       'importances': feature_importances.importances_mean,\n                       'std_err': feature_importances.importances_std,\n                      }).sort_values('importances', ascending=False)\n    \n    fig, ax = plt.subplots(figsize=(15, df.shape[0]/3), dpi=PLOT_DPI)\n    \n    sns.barplot(\n                x=df.importances,\n                y=df.features,\n                xerr=df.std_err,\n                color='steelblue',\n               )\n    \n    ax.set_title(f'{chart_title}')\n    ax.set_xlim(-0.02,)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.718775Z","iopub.execute_input":"2023-07-31T09:46:48.719250Z","iopub.status.idle":"2023-07-31T09:46:48.733386Z","shell.execute_reply.started":"2023-07-31T09:46:48.719170Z","shell.execute_reply":"2023-07-31T09:46:48.732289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_model_metrics(models, X_train, Y_train, X_valid, Y_valid, cv=N_CV, scoring_list=['f1', 'neg_log_loss']):\n    '''\n    Accepts:\n    - dataframe with a list of models and their characteristics;\n    - two datasets (features and target) - training and validation sets;\n    - cv parameter for cross_val_score;\n    - a list of metrics.\n    \n    For each model in the dataframe, it adds the specified metrics for both datasets.\n    '''\n\n    def cv_score(model, X, Y, scoring, cv):\n        invert_koeff = -1 if scoring.split('_')[0] == 'neg' else 1   # invert metrics prefixed with \"neg_\"\n        if scoring == 'neg_log_loss':\n            return -1 * cross_val_score(model, X, Y, scoring=scoring, cv=cv, n_jobs=-1, method='predict_proba').mean()\n        else:\n            return invert_koeff * cross_val_score(model, X, Y, scoring=scoring, cv=cv, n_jobs=-1).mean()\n    \n    for scoring in scoring_list:\n    \n        # model results on the training set (cross-validation averaging)\n        models[scoring + '_train'] = models.model.apply(cv_score, args=(X_train, Y_train, scoring, cv))\n\n        # results of models on the test set (averaging over cross-validation)\n        models[scoring + '_valid'] = models.model.apply(cv_score , args=(X_valid, Y_valid, scoring, cv))\n    \n    # optimal hyperparameters\n    models['best_params'] = models.study.apply(lambda model: model.best_params)\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.734940Z","iopub.execute_input":"2023-07-31T09:46:48.736208Z","iopub.status.idle":"2023-07-31T09:46:48.750810Z","shell.execute_reply.started":"2023-07-31T09:46:48.736154Z","shell.execute_reply":"2023-07-31T09:46:48.749322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_final_features(pipeline_model):\n    '''\n    Accepts pipeline.\n    Returns a list of features on which the final estimator of the pipeline is trained.\n    '''\n    feature_list = []\n    \n    for feature in pipeline_model.steps[-2][1].get_feature_names_out():\n        feature_list.append(feature.split('__')[1])\n\n    return feature_list","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.752827Z","iopub.execute_input":"2023-07-31T09:46:48.753373Z","iopub.status.idle":"2023-07-31T09:46:48.766980Z","shell.execute_reply.started":"2023-07-31T09:46:48.753305Z","shell.execute_reply":"2023-07-31T09:46:48.765941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_feature_importances(chart_title, feature_names, feature_importances):\n    '''\n    Displays a graph of the importance of the features used by the model.\n\n    :chart_title: chart title\n    :feature_names: feature names\n    :feature_importances: feature importance\n    '''\n\n    fig, ax = plt.subplots(figsize=(15, 5), dpi=PLOT_DPI)\n\n    df = pd.DataFrame({'features': feature_names,\n                       'importances': feature_importances.importances_mean,\n                       'std_err': feature_importances.importances_std\n                       }).sort_values('importances', ascending=False)\n\n    sns.barplot(x='importances', y='features', data=df, xerr=df.std_err, color='hotpink')\n\n    ax.set_title(chart_title)\n    ax.set_xlabel('Importance')\n    ax.set_ylabel('Features')\n    ax.set_xlim(0, None)\n    ax.grid(True, axis='x')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.769117Z","iopub.execute_input":"2023-07-31T09:46:48.770083Z","iopub.status.idle":"2023-07-31T09:46:48.780752Z","shell.execute_reply.started":"2023-07-31T09:46:48.770035Z","shell.execute_reply":"2023-07-31T09:46:48.779157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_dataset(df):\n    \"\"\"\n    Clears the dataset from extra spaces and other values,\n    which can create non-obvious duplicates in the data.\n\n    :param dataset: source dataset (pandas DataFrame)\n    :return: cleared dataset (pandas DataFrame)\n    \"\"\"\n    cleaned_data = df.copy()  # create a copy of the original dataset for changes\n\n   # Clear values from extra spaces\n    cleaned_data = cleaned_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\n   # Remove duplicates\n    cleaned_data = cleaned_data.drop_duplicates()\n\n    return cleaned_data","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.782647Z","iopub.execute_input":"2023-07-31T09:46:48.783463Z","iopub.status.idle":"2023-07-31T09:46:48.796635Z","shell.execute_reply.started":"2023-07-31T09:46:48.783411Z","shell.execute_reply":"2023-07-31T09:46:48.795435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Settings","metadata":{}},{"cell_type":"code","source":"# TextStyle\n\nclass f:    \n    BOLD = \"\\033[1m\"     # Bold text\n    ITALIC = \"\\033[3m\"   # Italic text\n    END = \"\\033[0m\"      # Reset style","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.798808Z","iopub.execute_input":"2023-07-31T09:46:48.799756Z","iopub.status.idle":"2023-07-31T09:46:48.808844Z","shell.execute_reply.started":"2023-07-31T09:46:48.799703Z","shell.execute_reply":"2023-07-31T09:46:48.807525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matplotlib, Seaborn\n\nPLOT_DPI = 150 # dpi for drawing charts\nsns.set_style('whitegrid', {'axes.facecolor': '0.98', 'grid.color': '0.9', 'axes.edgecolor': '1.0'})\nplt.rc('axes', labelweight='bold', titlesize=16, titlepad=10)\n\n# Plotly Graph_Objects\npio.templates['my_theme'] = go.layout.Template(\n    layout_autosize=True,\n    layout_height=200,\n    layout_legend_orientation=\"h\",\n    layout_margin=dict(t=40, b=40),\n    layout_template='seaborn'\n)\npio.templates.default = 'my_theme'\n\n# colors, color schemes\nCMAP_SYMMETRIC = LinearSegmentedColormap.from_list('', ['gray', 'steelblue', 'hotpink'])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:48.814708Z","iopub.execute_input":"2023-07-31T09:46:48.815994Z","iopub.status.idle":"2023-07-31T09:46:50.669767Z","shell.execute_reply.started":"2023-07-31T09:46:48.815902Z","shell.execute_reply":"2023-07-31T09:46:50.668386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pandas defaults\n\npd.options.display.max_colwidth = 100\npd.options.display.max_rows = 500\npd.options.display.max_columns = 100\npd.options.display.float_format = '{:.3f}'.format\npd.options.display.colheader_justify = 'left'","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.672506Z","iopub.execute_input":"2023-07-31T09:46:50.673072Z","iopub.status.idle":"2023-07-31T09:46:50.681575Z","shell.execute_reply.started":"2023-07-31T09:46:50.673021Z","shell.execute_reply":"2023-07-31T09:46:50.679816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optuna design\n\noptuna.logging.set_verbosity(optuna.logging.WARNING) # disable logging when optuna is running","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.687572Z","iopub.execute_input":"2023-07-31T09:46:50.689043Z","iopub.status.idle":"2023-07-31T09:46:50.704981Z","shell.execute_reply.started":"2023-07-31T09:46:50.688996Z","shell.execute_reply":"2023-07-31T09:46:50.703746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Disable warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.707040Z","iopub.execute_input":"2023-07-31T09:46:50.707905Z","iopub.status.idle":"2023-07-31T09:46:50.717302Z","shell.execute_reply.started":"2023-07-31T09:46:50.707849Z","shell.execute_reply":"2023-07-31T09:46:50.715770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read and validate data","metadata":{}},{"cell_type":"code","source":"# Path to data \n\npath_greeks = '/kaggle/input/icr-identify-age-related-conditions/greeks.csv'\npath_train = '/kaggle/input/icr-identify-age-related-conditions/train.csv'\npath_test = '/kaggle/input/icr-identify-age-related-conditions/test.csv'\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.719233Z","iopub.execute_input":"2023-07-31T09:46:50.719703Z","iopub.status.idle":"2023-07-31T09:46:50.729924Z","shell.execute_reply.started":"2023-07-31T09:46:50.719667Z","shell.execute_reply":"2023-07-31T09:46:50.728689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading data \n\ngreeks_data = pd.read_csv(path_greeks)\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.731651Z","iopub.execute_input":"2023-07-31T09:46:50.732060Z","iopub.status.idle":"2023-07-31T09:46:50.831083Z","shell.execute_reply.started":"2023-07-31T09:46:50.732029Z","shell.execute_reply":"2023-07-31T09:46:50.829645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging data\n\nmerged_data = pd.merge(train_data, greeks_data, on='Id', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.832870Z","iopub.execute_input":"2023-07-31T09:46:50.833449Z","iopub.status.idle":"2023-07-31T09:46:50.863857Z","shell.execute_reply.started":"2023-07-31T09:46:50.833402Z","shell.execute_reply":"2023-07-31T09:46:50.862540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explore_dataframe(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:50.865738Z","iopub.execute_input":"2023-07-31T09:46:50.866646Z","iopub.status.idle":"2023-07-31T09:46:51.290739Z","shell.execute_reply.started":"2023-07-31T09:46:50.866605Z","shell.execute_reply":"2023-07-31T09:46:51.289462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After examining the received data on the training set (`train_data`), we can draw the following conclusions:\n\n**Data type:** Most of the columns are of type `float64`, except for the `\"Id\"`, `\"EJ\"` and `\"Class\"` columns. The `\"Class\"` column is of type `int64` and the `\"EJ\"` column is of type `object`\n\n**Missing values:** Some columns contain missing values. The columns `\"BQ\"`, `\"DU\"`, `\"DV\"`, `\"EL\"`, `\"FC\"`, `\"FL\"`, and `\"FS\"` have a small number of missing values\n\n**Unique Values:** Each column has a different number of unique values. Some columns have a large number of unique values, for example, the `\"BD\"` column has 617 unique values, and the `\"BQ\"` column has 515 unique values. This is due to the fact that one hundred specified columns contain individual health indicators.\n\n**Columns:** Column names are presented in the `\"Column\"` column. They include `AB, AF, AH, AM, AR, AX, AY, AZ` and so on\n\n**Target variable:** The `\"Class\"` column is the target variable. It contains two unique values: 0 and 1, which indicate the absence or presence of the disease, respectively.\n\n**Overall output:** The training dataset (`train_data`) contains many features represented by numerical values. Some columns contain missing values that may need to be processed. The \"Class\" column is the target variable to be predicted. This data will be useful for training the model and predicting the presence of a disease based on input features.","metadata":{}},{"cell_type":"code","source":"explore_dataframe(merged_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:51.292375Z","iopub.execute_input":"2023-07-31T09:46:51.292794Z","iopub.status.idle":"2023-07-31T09:46:51.722383Z","shell.execute_reply.started":"2023-07-31T09:46:51.292758Z","shell.execute_reply":"2023-07-31T09:46:51.721159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Having studied the obtained data on the merged data set `(merged_data)`, we can draw the following conclusions:\n\n**Data type:** Most of the columns are of type float64, except for the columns `\"Id\"`, `\"EJ\"`, `\"Alpha\"`, `\"Beta\"`, `\"Gamma\"`, `\"Delta\" ` and `\"Class\"`\nThe `\"Class\"` column is of type int64, and the `\"Id\"`, `\"EJ\"`, `\"Alpha\"`, `\"Beta\"`, `\"Gamma\"` and `\"Delta\"` columns are of type object\n\n**Missing values:** Some columns contain missing values. The columns `\"BQ\"`, `\"DU\"`, `\"FL\"` and `\"FC\"` have a small number of missing values, and the column `\"EL\"` has 60 missing values\n\n**Unique Values:** Each column has a different number of unique values. Some columns have a large number of unique values. For example, the `\"BD\"` column has 617 unique values, and the `\"Epsilon\"` column has 198 unique values. This is due to the fact that one hundred specified columns contain individual health indicators.\n\n**Columns:** Column names are presented in the `\"Column\"` column. They include `AB, AF, AH, AM, AR, AX, AY, AZ` and so on\n\n**Target variable:** The `\"Class\"` column is the target variable. It contains two unique values: 0 and 1, which indicate the absence or presence of the disease, respectively.\n\n**Additional metadata:** The merged dataset also contains additional columns such as `\"Alpha\"`, `\"Beta\"`, `\"Gamma\"`, `\"Delta\"` and `\"Epsilon\"`. They are of type object and contain information about the type of age state and experimental characteristics.\n\n**Overall conclusion:** The merged dataset (`merged_data`) contains extended information about health traits, including data from the training set and additional metadata. Most features are represented by numeric values, but there are also categorical columns. Some columns contain missing values that may need to be processed. The \"Class\" column is the target variable, and additional columns may contain important information for analysis and prediction","metadata":{}},{"cell_type":"code","source":"explore_dataframe(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:51.724612Z","iopub.execute_input":"2023-07-31T09:46:51.725018Z","iopub.status.idle":"2023-07-31T09:46:52.082198Z","shell.execute_reply.started":"2023-07-31T09:46:51.724980Z","shell.execute_reply":"2023-07-31T09:46:52.081254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data correction","metadata":{}},{"cell_type":"code","source":"train_data = clean_dataset(train_data)\nmerged_data = clean_dataset(merged_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.083833Z","iopub.execute_input":"2023-07-31T09:46:52.084247Z","iopub.status.idle":"2023-07-31T09:46:52.182712Z","shell.execute_reply.started":"2023-07-31T09:46:52.084212Z","shell.execute_reply":"2023-07-31T09:46:52.181400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The folder train_data contains a small number of gaps in the columns of individual health indicators, we will replace them with the median\n\nmedian_BQ = train_data['BQ'].median()\ntrain_data['BQ'].fillna(median_BQ, inplace=True)\n\nmedian_EL = train_data['EL'].median()\ntrain_data['EL'].fillna(median_EL, inplace=True)\n\nmedian_DU = train_data['DU'].median()\ntrain_data['DU'].fillna(median_DU, inplace=True)\n\nmedian_FC = train_data['FC'].median()\ntrain_data['FC'].fillna(median_FC, inplace=True)\n\nmedian_FL = train_data['FL'].median()\ntrain_data['FL'].fillna(median_FL, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.184418Z","iopub.execute_input":"2023-07-31T09:46:52.184817Z","iopub.status.idle":"2023-07-31T09:46:52.201363Z","shell.execute_reply.started":"2023-07-31T09:46:52.184782Z","shell.execute_reply":"2023-07-31T09:46:52.200134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The merged_data folder contains a small number of gaps in the columns of individual health indicators, we will replace them with the median\n\nmedian_BQ = merged_data['BQ'].median()\nmerged_data['BQ'].fillna(median_BQ, inplace=True)\n\nmedian_EL = merged_data['EL'].median()\nmerged_data['EL'].fillna(median_EL, inplace=True)\n\nmedian_DU = merged_data['DU'].median()\nmerged_data['DU'].fillna(median_DU, inplace=True)\n\nmedian_FC = merged_data['FC'].median()\nmerged_data['FC'].fillna(median_FC, inplace=True)\n\nmedian_FL = merged_data['FL'].median()\nmerged_data['FL'].fillna(median_FL, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.202694Z","iopub.execute_input":"2023-07-31T09:46:52.203173Z","iopub.status.idle":"2023-07-31T09:46:52.222188Z","shell.execute_reply.started":"2023-07-31T09:46:52.203133Z","shell.execute_reply":"2023-07-31T09:46:52.220909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the categorical value of the category column of individual health indicators\n\nprint(train_data['EJ'].unique())\nprint(merged_data['EJ'].unique())","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.224620Z","iopub.execute_input":"2023-07-31T09:46:52.225601Z","iopub.status.idle":"2023-07-31T09:46:52.234764Z","shell.execute_reply.started":"2023-07-31T09:46:52.225549Z","shell.execute_reply":"2023-07-31T09:46:52.233317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix the EJ column type to a binary value\n\n# train_data['EJ'] = train_data['EJ'].replace({'A': 0, 'B': 1})\n# test_data['EJ'] = test_data['EJ'].replace({'A': 0, 'B': 1})\nmerged_data['EJ'] = merged_data['EJ'].replace({'A': 0, 'B': 1})","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.237139Z","iopub.execute_input":"2023-07-31T09:46:52.237900Z","iopub.status.idle":"2023-07-31T09:46:52.248393Z","shell.execute_reply.started":"2023-07-31T09:46:52.237860Z","shell.execute_reply":"2023-07-31T09:46:52.247218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # # Check the result\n\n# print(merged_data.info())","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.250947Z","iopub.execute_input":"2023-07-31T09:46:52.252291Z","iopub.status.idle":"2023-07-31T09:46:52.260172Z","shell.execute_reply.started":"2023-07-31T09:46:52.252236Z","shell.execute_reply":"2023-07-31T09:46:52.258699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correction of duplicates","metadata":{}},{"cell_type":"code","source":"duplicates_train = train_data.duplicated()\nprint(\"Number of duplicates in train_data:\", duplicates_train.sum())","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.262121Z","iopub.execute_input":"2023-07-31T09:46:52.262596Z","iopub.status.idle":"2023-07-31T09:46:52.283860Z","shell.execute_reply.started":"2023-07-31T09:46:52.262560Z","shell.execute_reply":"2023-07-31T09:46:52.282848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicates_merged = merged_data.duplicated()\nprint(\"Number of duplicates in merged_data:\", duplicates_merged.sum())","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.285642Z","iopub.execute_input":"2023-07-31T09:46:52.286355Z","iopub.status.idle":"2023-07-31T09:46:52.306281Z","shell.execute_reply.started":"2023-07-31T09:46:52.286296Z","shell.execute_reply":"2023-07-31T09:46:52.305259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No duplicates - excellent","metadata":{}},{"cell_type":"markdown","source":"# Investigate features for errors and outliers\n","metadata":{}},{"cell_type":"markdown","source":"### Graphs of scatter of numerical features","metadata":{}},{"cell_type":"markdown","source":"> Let's study the training set, since merge_data is identical in numerical terms, then consider one dataset:","metadata":{}},{"cell_type":"code","source":"print(f'\\nScatter plots of numerical features\\n')\n\nnum_features = train_data.select_dtypes(include=np.number).columns.to_list()\n\nfor feature in num_features:\n    fig, ax = plt.subplots(figsize=(15, 0.5), dpi=100)\n    sns.boxplot(data=train_data, x=feature, color='lightgray', flierprops={'marker': '.', 'markeredgecolor': '#FF00FF', 'markersize': 1})\n    ax.set_xticklabels(ax.get_xticks(), fontsize=8)  # Decreasing the font size of labels along the x-axis\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:46:52.307821Z","iopub.execute_input":"2023-07-31T09:46:52.308440Z","iopub.status.idle":"2023-07-31T09:47:05.918277Z","shell.execute_reply.started":"2023-07-31T09:46:52.308402Z","shell.execute_reply":"2023-07-31T09:47:05.916993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see fairly confident indicators in the data, there are outliers, but since we have individual medical data sets in numerical values, it is obvious that in this case we define an outlier as a variant of the indicator","metadata":{}},{"cell_type":"markdown","source":"### Check the minimum and maximum values of some features","metadata":{}},{"cell_type":"code","source":"# value_counts = merged_data['Epsilon'].value_counts()\n# print(value_counts)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:05.919917Z","iopub.execute_input":"2023-07-31T09:47:05.920303Z","iopub.status.idle":"2023-07-31T09:47:05.925564Z","shell.execute_reply.started":"2023-07-31T09:47:05.920269Z","shell.execute_reply":"2023-07-31T09:47:05.924254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data['Epsilon'] = pd.to_datetime(merged_data['Epsilon'], errors='coerce')\n\n# Checking the minimum and maximum date\n\nmin_date = merged_data['Epsilon'].min()\nmax_date = merged_data['Epsilon'].max()\n\nprint('Minimum date:', min_date)\nprint('Maximum date:', max_date)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:05.927173Z","iopub.execute_input":"2023-07-31T09:47:05.928355Z","iopub.status.idle":"2023-07-31T09:47:05.952179Z","shell.execute_reply.started":"2023-07-31T09:47:05.928286Z","shell.execute_reply":"2023-07-31T09:47:05.950596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">Data for the study were collected over a period of >8 years. Also, I will not remove dates with a small number of results.\n>\n>The fact that all the data in the test set was collected after the training set was collected may affect the results of the model and the interpretation of those results\n>\n>Here are a few factors that might be important:\n\n>`Temporal features:` If the data in the test set represents newer information, then it may reflect changes over time, such as new trends or events. In such a case, a model trained on old data may not be accurate enough to predict new data.\n\n>`Possibility of overfitting:` If the test set was collected after the training set, there is a risk of overfitting the model on the training data and then accurately predicting the same data in the test set. This can lead to an overestimation of the accuracy of the model.\n\n>`Different data collection conditions:` If the data in the test set were collected under different conditions or using different methods, this may lead to differences in data distribution. In this case, a model trained on some data may not be able to predict well on other data.\n\n**NB!Given these points, be careful when interpreting model results, especially if the test dataset contains newer information**","metadata":{}},{"cell_type":"markdown","source":"### Values of categorical features","metadata":{}},{"cell_type":"markdown","source":"> Let's study the training set, only merge_data contains categorical features, then we will consider it:","metadata":{}},{"cell_type":"code","source":"# Count the number of unique values\n\ndef count_unique_values(data):\n    for column in data.select_dtypes(include='object'):\n        if column != 'Id':  \n            unique_values = data[column].value_counts()\n            print(f\"Unique values for a column {column}:\")\n            print(unique_values)\n            print()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:05.953952Z","iopub.execute_input":"2023-07-31T09:47:05.954485Z","iopub.status.idle":"2023-07-31T09:47:05.965161Z","shell.execute_reply.started":"2023-07-31T09:47:05.954441Z","shell.execute_reply":"2023-07-31T09:47:05.963690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_unique_values(merged_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:05.966825Z","iopub.execute_input":"2023-07-31T09:47:05.967320Z","iopub.status.idle":"2023-07-31T09:47:05.986830Z","shell.execute_reply.started":"2023-07-31T09:47:05.967277Z","shell.execute_reply":"2023-07-31T09:47:05.985199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_bar_charts(data):\n    categorical_columns = data.select_dtypes(include='object').columns\n    for column in categorical_columns:\n        if column != 'Id':\n            fig, ax = plt.subplots(figsize=(6, 4))\n            sns.countplot(data=data, x=column, palette=['gray', 'hotpink'])\n            sns.despine()\n            ax.set_xlabel(column)\n            ax.set_ylabel('Count')\n            ax.set_title(f\"Distribution of {column}\")\n            plt.show()\nplot_bar_charts(merged_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:05.988767Z","iopub.execute_input":"2023-07-31T09:47:05.989318Z","iopub.status.idle":"2023-07-31T09:47:07.257151Z","shell.execute_reply.started":"2023-07-31T09:47:05.989252Z","shell.execute_reply":"2023-07-31T09:47:07.256125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see:\n\n> `Alpha` - Specifies the type of age state, if present:\n>\n>**A**- No age-related changes `(0)`\n>\n>**B** \\\n>\n>**D** - Three age states of change `(1)` I'll assume it's a straight line with Beta, Gamma, Delta\n>\n>**G** /\n>\n> `Beta, Gamma, Delta` - Three experimental characteristics, their detailed characteristics are hidden under the symbols `A - M `\n\nRespectively:\n\n**Alpha** has an indicator A - predominantly; B | G | D - descending respectively\n\n**Beta** has C index - mainly; B | A - descending respectively\n\n**Gamma** has an indicator M - predominantly; N | H | B | A | F | G | E - descending respectively\n\n**Delta** has an indicator B - predominantly; A | C | D - descending respectively","metadata":{}},{"cell_type":"markdown","source":"### Check the distribution of values of the target variable Class in the training set","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.hist(train_data['Class'], bins=50, color='grey')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('Distribution of Class')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:07.258672Z","iopub.execute_input":"2023-07-31T09:47:07.259105Z","iopub.status.idle":"2023-07-31T09:47:07.780774Z","shell.execute_reply.started":"2023-07-31T09:47:07.259067Z","shell.execute_reply":"2023-07-31T09:47:07.779252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Research part","metadata":{}},{"cell_type":"markdown","source":"For the research part and creating new features, you do not need to create a copy of the training dataset, since we will be experimenting on merged_data. Then it will be possible to experiment with creating new features and adding them to the model training pipeline","metadata":{}},{"cell_type":"markdown","source":"### New features\n\nLists for easy tracking of new features","metadata":{}},{"cell_type":"code","source":"new_num_features_list = []\nnew_cat_features_list = []","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:07.782692Z","iopub.execute_input":"2023-07-31T09:47:07.783171Z","iopub.status.idle":"2023-07-31T09:47:07.790331Z","shell.execute_reply.started":"2023-07-31T09:47:07.783129Z","shell.execute_reply":"2023-07-31T09:47:07.788780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selection of features for counting the number of values\nfeature_columns = merged_data.columns[1:57]\n\n# Threshold value for determining \"Popular Feature\"\npopularity_threshold = 300\n\n# Create a new feature \"Popular Feature\"\nmerged_data['Popular Feature'] = merged_data[feature_columns].nunique(axis=1) > popularity_threshold\n\n# Creation of a new feature \"Type of age state\"\nage_state_columns = ['Alpha', 'Beta', 'Gamma', 'Delta']\nmerged_data['Age State'] = merged_data[age_state_columns].mode(axis=1)[0]\n\n# Output updated dataframe\nmerged_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:07.792147Z","iopub.execute_input":"2023-07-31T09:47:07.792673Z","iopub.status.idle":"2023-07-31T09:47:08.793950Z","shell.execute_reply.started":"2023-07-31T09:47:07.792627Z","shell.execute_reply":"2023-07-31T09:47:08.792613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result, new features have been created:\n\n`\"Popular Feature\"` - contains the values False or True, which tells us if this feature meets the popularity criteria\n`\"Age State\"` - which will contain the number of unique types of age states that occur more often in this Id (relevant if 'Alpha', 'Beta', 'Gamma', 'Delta' use the same designations)","metadata":{}},{"cell_type":"code","source":"if merged_data['Popular Feature'].dtype != 'object':\n    new_num_features_list.append('Popular Feature')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.809799Z","iopub.execute_input":"2023-07-31T09:47:08.810296Z","iopub.status.idle":"2023-07-31T09:47:08.816876Z","shell.execute_reply.started":"2023-07-31T09:47:08.810255Z","shell.execute_reply":"2023-07-31T09:47:08.815402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if merged_data['Age State'].dtype == 'object':\n    new_cat_features_list.append('Age State')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.818869Z","iopub.execute_input":"2023-07-31T09:47:08.819388Z","iopub.status.idle":"2023-07-31T09:47:08.831111Z","shell.execute_reply.started":"2023-07-31T09:47:08.819318Z","shell.execute_reply":"2023-07-31T09:47:08.829773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Target Encoding of categorical features","metadata":{}},{"cell_type":"code","source":"def target_encode(df, feature_list, target, agg_func_list=['mean'], fill_na=0):\n    '''\n     Takes a dataframe and a feature_list and makes a new feature for it,\n     using target encoding and a given aggregation function agg_func.\n     Additionally stores the name of the new feature in new_num_features_list\n     (this is only needed in this section: checking correlations, mutual info, etc.)\n    '''\n    \n    for agg_func in agg_func_list:\n        \n        new_feature = '_'.join(feature_list) + '_TRG_' + agg_func\n        df[new_feature] = df.groupby(feature_list)[target].transform(agg_func) #.fillna(fill_na)\n        \n        new_num_features_list.append(new_feature)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.833189Z","iopub.execute_input":"2023-07-31T09:47:08.833667Z","iopub.status.idle":"2023-07-31T09:47:08.844054Z","shell.execute_reply.started":"2023-07-31T09:47:08.833624Z","shell.execute_reply":"2023-07-31T09:47:08.842806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pair_cat_feature_target_mean(df):\n    '''\n    iterates over all categorical features in pairs;\n    for each pair creates a new feature using mean target encoding\n    '''\n    cat_features = df.select_dtypes(exclude=np.number).columns.to_list()   # list of categorical features\n    n_cat_features = len(cat_features)                                     # number of categorical features\n    \n    for i in range(n_cat_features):\n        for j in range(i+1, n_cat_features):\n            df = target_encode(\n                               df,\n                               feature_list=[cat_features[i], cat_features[j]],\n                               target=TARGET,\n                               agg_func_list=['mean'],\n                              )\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.846414Z","iopub.execute_input":"2023-07-31T09:47:08.846968Z","iopub.status.idle":"2023-07-31T09:47:08.858681Z","shell.execute_reply.started":"2023-07-31T09:47:08.846915Z","shell.execute_reply":"2023-07-31T09:47:08.857306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data = pair_cat_feature_target_mean(merged_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.862473Z","iopub.execute_input":"2023-07-31T09:47:08.863083Z","iopub.status.idle":"2023-07-31T09:47:08.942497Z","shell.execute_reply.started":"2023-07-31T09:47:08.863029Z","shell.execute_reply":"2023-07-31T09:47:08.940983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.944789Z","iopub.execute_input":"2023-07-31T09:47:08.945371Z","iopub.status.idle":"2023-07-31T09:47:08.979666Z","shell.execute_reply.started":"2023-07-31T09:47:08.945295Z","shell.execute_reply":"2023-07-31T09:47:08.977927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### New feature for combination Class + Popular Feature + Age State\n\nThis will allow the model to take into account possible relationships and the influence of a combination of these factors on the presence of age-related changes that change the state","metadata":{}},{"cell_type":"code","source":"def named_cat_feature_target_mean(df, feature_list):\n    '''\n    For the given list of categorical features, creates a new feature using mean target encoding\n    '''\n    df = target_encode(\n                       df,\n                       feature_list=feature_list,\n                       target=TARGET,\n                       agg_func_list=['mean']\n                      )\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.981464Z","iopub.execute_input":"2023-07-31T09:47:08.982355Z","iopub.status.idle":"2023-07-31T09:47:08.988488Z","shell.execute_reply.started":"2023-07-31T09:47:08.982281Z","shell.execute_reply":"2023-07-31T09:47:08.987443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data = pair_cat_feature_target_mean(merged_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:08.990059Z","iopub.execute_input":"2023-07-31T09:47:08.991052Z","iopub.status.idle":"2023-07-31T09:47:09.060811Z","shell.execute_reply.started":"2023-07-31T09:47:08.991011Z","shell.execute_reply":"2023-07-31T09:47:09.059437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:09.062419Z","iopub.execute_input":"2023-07-31T09:47:09.063442Z","iopub.status.idle":"2023-07-31T09:47:09.091420Z","shell.execute_reply.started":"2023-07-31T09:47:09.063399Z","shell.execute_reply":"2023-07-31T09:47:09.090152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data.dropna(inplace=True)\nmerged_data.reset_index(drop=True, inplace=True)\n\nmerged_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:09.093161Z","iopub.execute_input":"2023-07-31T09:47:09.093741Z","iopub.status.idle":"2023-07-31T09:47:09.124270Z","shell.execute_reply.started":"2023-07-31T09:47:09.093702Z","shell.execute_reply":"2023-07-31T09:47:09.123375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data.to_csv('/kaggle/working/merged_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:09.125756Z","iopub.execute_input":"2023-07-31T09:47:09.126392Z","iopub.status.idle":"2023-07-31T09:47:09.196985Z","shell.execute_reply.started":"2023-07-31T09:47:09.126355Z","shell.execute_reply":"2023-07-31T09:47:09.195585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Perhaps the use of this file (merged_data) will be useful for an alternative research with additional features available in it that can expand the boundaries of the research","metadata":{}},{"cell_type":"code","source":"# List of interval features\n\ninterval_features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN', 'BP', 'BQ', 'BR',\n                     'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU', 'CW', 'DA', 'DE', 'DF', \n                     'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY','EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU', \n                     'FC', 'FD', 'FE', 'FI', 'FL','FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'] + new_num_features_list","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:09.198664Z","iopub.execute_input":"2023-07-31T09:47:09.199104Z","iopub.status.idle":"2023-07-31T09:47:09.207119Z","shell.execute_reply.started":"2023-07-31T09:47:09.199066Z","shell.execute_reply":"2023-07-31T09:47:09.205900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = merged_data.phik_matrix(interval_cols=interval_features)\n\nfig, ax = plt.subplots(figsize=(15, 0.4*df.shape[1]), dpi=100)\nsns.heatmap(df[(0.3 < df) & (df < 1.0)], annot=False, cbar=False, linewidths=0.2, cmap='Blues')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:09.208777Z","iopub.execute_input":"2023-07-31T09:47:09.209511Z","iopub.status.idle":"2023-07-31T09:47:47.749694Z","shell.execute_reply.started":"2023-07-31T09:47:09.209452Z","shell.execute_reply":"2023-07-31T09:47:47.748266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntarget_correlation_significance(merged_data, TARGET, interval_features)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:47:47.752217Z","iopub.execute_input":"2023-07-31T09:47:47.753087Z","iopub.status.idle":"2023-07-31T09:53:47.980731Z","shell.execute_reply.started":"2023-07-31T09:47:47.753025Z","shell.execute_reply":"2023-07-31T09:53:47.979591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analyzing the correlation matrix, we can draw the following conclusions:\n\nSome features have a positive correlation close to `1.0`, which indicates a strong relationship between them. For example, `Alpha_Gamma_TRG_mean`, `Id_Popular Feature_TRG_mean` and `Id_Age State_TRG_mean` have a positive correlation close to 1.0\nSome features have a negative correlation close to -1.0. For example, `FS` is negatively correlated, which may indicate an inverse relationship with other features\nSome features have a low correlation close to 0, which means there is no linear relationship between them. ","metadata":{}},{"cell_type":"code","source":"merged_data = \"/kaggle/working/merged_data.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:55:15.200588Z","iopub.execute_input":"2023-07-31T09:55:15.201586Z","iopub.status.idle":"2023-07-31T09:55:15.207193Z","shell.execute_reply.started":"2023-07-31T09:55:15.201538Z","shell.execute_reply":"2023-07-31T09:55:15.205906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset **merged_data** might be useful for your future research, as it contains additional features, including combinations of those present in the standard dataset","metadata":{}},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"del df","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:58:50.299264Z","iopub.execute_input":"2023-07-31T09:58:50.299787Z","iopub.status.idle":"2023-07-31T09:58:50.305142Z","shell.execute_reply.started":"2023-07-31T09:58:50.299745Z","shell.execute_reply":"2023-07-31T09:58:50.304089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation\n\nFeature extraction and target variable","metadata":{}},{"cell_type":"code","source":"train_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:58:55.430187Z","iopub.execute_input":"2023-07-31T09:58:55.430651Z","iopub.status.idle":"2023-07-31T09:58:55.464846Z","shell.execute_reply.started":"2023-07-31T09:58:55.430614Z","shell.execute_reply":"2023-07-31T09:58:55.463967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data.drop('Class', axis=1)\nY = train_data['Class']","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:58:57.620693Z","iopub.execute_input":"2023-07-31T09:58:57.621139Z","iopub.status.idle":"2023-07-31T09:58:57.629142Z","shell.execute_reply.started":"2023-07-31T09:58:57.621107Z","shell.execute_reply":"2023-07-31T09:58:57.628223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, Y.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:02.017229Z","iopub.execute_input":"2023-07-31T09:59:02.017752Z","iopub.status.idle":"2023-07-31T09:59:02.024610Z","shell.execute_reply.started":"2023-07-31T09:59:02.017710Z","shell.execute_reply":"2023-07-31T09:59:02.023662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VALID_FRAC = 0.2\n\nif VALID_FRAC > 0:\n    X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=VALID_FRAC, random_state=RS)\nelse:\n    X_train, X_valid, Y_train, Y_valid = X, X, Y, Y","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:08.621613Z","iopub.execute_input":"2023-07-31T09:59:08.622081Z","iopub.status.idle":"2023-07-31T09:59:08.631323Z","shell.execute_reply.started":"2023-07-31T09:59:08.622045Z","shell.execute_reply":"2023-07-31T09:59:08.629797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:15.276406Z","iopub.execute_input":"2023-07-31T09:59:15.277025Z","iopub.status.idle":"2023-07-31T09:59:15.285319Z","shell.execute_reply.started":"2023-07-31T09:59:15.276979Z","shell.execute_reply":"2023-07-31T09:59:15.284381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_valid.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:17.670570Z","iopub.execute_input":"2023-07-31T09:59:17.671034Z","iopub.status.idle":"2023-07-31T09:59:17.676412Z","shell.execute_reply.started":"2023-07-31T09:59:17.671001Z","shell.execute_reply":"2023-07-31T09:59:17.675145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class column_dropper_transformer(BaseEstimator, TransformerMixin):\n\n    def __init__(self, drop_columns):\n        self.drop_columns = drop_columns\n\n    def fit(self, X, Y=None):\n        return self\n        \n    def transform(self, X, Y=None):\n        return X.drop(self.drop_columns, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:19.421828Z","iopub.execute_input":"2023-07-31T09:59:19.422654Z","iopub.status.idle":"2023-07-31T09:59:19.429416Z","shell.execute_reply.started":"2023-07-31T09:59:19.422616Z","shell.execute_reply":"2023-07-31T09:59:19.428058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of features to remove\ndrop_columns = ['Id']\n\ncolumn_dropper = column_dropper_transformer(drop_columns)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:23.178912Z","iopub.execute_input":"2023-07-31T09:59:23.180037Z","iopub.status.idle":"2023-07-31T09:59:23.185656Z","shell.execute_reply.started":"2023-07-31T09:59:23.179971Z","shell.execute_reply":"2023-07-31T09:59:23.184661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"#### Categorical features","metadata":{}},{"cell_type":"code","source":"cat_features = list(set(X_train.select_dtypes(exclude='number').columns.to_list()))\ncat_features","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:27.111306Z","iopub.execute_input":"2023-07-31T09:59:27.111823Z","iopub.status.idle":"2023-07-31T09:59:27.120593Z","shell.execute_reply.started":"2023-07-31T09:59:27.111782Z","shell.execute_reply":"2023-07-31T09:59:27.119508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selectors for numeric and categorical features","metadata":{}},{"cell_type":"code","source":"num_selector = make_column_selector(dtype_include=np.number)\ncat_selector = make_column_selector(dtype_exclude=np.number)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:31.927056Z","iopub.execute_input":"2023-07-31T09:59:31.927564Z","iopub.status.idle":"2023-07-31T09:59:31.933357Z","shell.execute_reply.started":"2023-07-31T09:59:31.927523Z","shell.execute_reply":"2023-07-31T09:59:31.932116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing of numeric and categorical features","metadata":{}},{"cell_type":"code","source":"# Preprocessing of numerical features\n\nnum_preprocessor = make_pipeline(\n                                 IterativeImputer(initial_strategy='mean', random_state=RS), \n                                 StandardScaler(),\n                                )","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:35.842733Z","iopub.execute_input":"2023-07-31T09:59:35.843688Z","iopub.status.idle":"2023-07-31T09:59:35.848736Z","shell.execute_reply.started":"2023-07-31T09:59:35.843649Z","shell.execute_reply":"2023-07-31T09:59:35.847702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for linear models\ncat_preprocessor_linr = OneHotEncoder(drop='first', handle_unknown='error')\n\n# for tree models\ncat_preprocessor_tree = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=9999)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:38.460362Z","iopub.execute_input":"2023-07-31T09:59:38.460882Z","iopub.status.idle":"2023-07-31T09:59:38.466598Z","shell.execute_reply.started":"2023-07-31T09:59:38.460823Z","shell.execute_reply":"2023-07-31T09:59:38.465624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Combining preprocessing of numeric and categorical features","metadata":{}},{"cell_type":"code","source":"# for linear models\npreprocessing_linr = make_column_transformer(\n                                             (num_preprocessor, num_selector),\n                                             (cat_preprocessor_linr, cat_selector),\n                                             remainder='passthrough'\n                                            )\n# for tree models\npreprocessing_tree = make_column_transformer(\n                                             (num_preprocessor, num_selector),\n                                             (cat_preprocessor_tree, cat_selector),\n                                             remainder='passthrough'\n                                            )\n# # for CatBoost\npreprocessing_catb = make_column_transformer(\n                                             (num_preprocessor, num_selector),\n                                             (cat_preprocessor_tree, cat_selector),\n                                             remainder='passthrough'\n                                            )","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:41.080637Z","iopub.execute_input":"2023-07-31T09:59:41.081473Z","iopub.status.idle":"2023-07-31T09:59:41.088616Z","shell.execute_reply.started":"2023-07-31T09:59:41.081426Z","shell.execute_reply":"2023-07-31T09:59:41.087492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"preprocessing_tree = make_column_transformer(\n    (num_preprocessor, num_selector),\n    (cat_preprocessor_tree, cat_selector),\n    (new_features_transformer, ['Id']),  # Используем новый преобразователь\n    remainder='passthrough'\n)","metadata":{}},{"cell_type":"code","source":"N_FEATURE_SELECT = 10 # was 10 changed to 50 and 25 and 15  - bad result","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:44.120520Z","iopub.execute_input":"2023-07-31T09:59:44.121027Z","iopub.status.idle":"2023-07-31T09:59:44.127090Z","shell.execute_reply.started":"2023-07-31T09:59:44.120983Z","shell.execute_reply":"2023-07-31T09:59:44.126024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_selector = SelectKBest(f_regression, k=N_FEATURE_SELECT)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:59:47.370694Z","iopub.execute_input":"2023-07-31T09:59:47.371202Z","iopub.status.idle":"2023-07-31T09:59:47.376977Z","shell.execute_reply.started":"2023-07-31T09:59:47.371156Z","shell.execute_reply":"2023-07-31T09:59:47.375916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The line `num_preprocessor = make_pipeline(IterativeImputer(initial_strategy='mean', random_state=RS), StandardScaler(),)` creates an instance of the Pipeline class that contains two transformers: `IterativeImpute`r and `StandardScaler`. These transformers are used to iteratively fill in missing numeric feature values using the 'mean' strategy and data standardization\n\n\n* Additionally, the code defines the transformers `cat_preprocessor_linr` and `cat_preprocessor_tree` for preprocessing categorical features depending on the model type. `cat_preprocessor_linr` uses the OHE (OneHotEncoder) centering method for linear models, and `cat_preprocessor_tree` uses the OrdinalEncoder method for tree-based models\n\n\n* As a result, the pipeline will combine all the transformers in the right order and allow you to process all the features at the same time to achieve the best result in the machine learning task","metadata":{}},{"cell_type":"markdown","source":"# Pipeline table","metadata":{}},{"cell_type":"code","source":"pipelines = [\n    Pipeline([\n        ('column_dropper', column_dropper),\n        ('preproc_tree', preprocessing_tree),\n        ('feature_selector', feature_selector),\n        ('DC', DummyClassifier())\n    ]),\n\n     Pipeline([\n        ('column_dropper', column_dropper),\n        ('preproc_tree', preprocessing_tree),\n        ('feature_selector', feature_selector),\n        ('XGBC', XGBClassifier(random_state=RS))\n    ]),\n\n    Pipeline([\n        ('column_dropper', column_dropper),\n        ('preproc_tree', preprocessing_tree),\n        ('feature_selector', feature_selector),\n        ('RFC', RandomForestClassifier(random_state=RS))\n    ]),\n\n    Pipeline([\n        ('column_dropper', column_dropper),\n        ('preproc_tree', preprocessing_tree),\n        ('feature_selector', feature_selector),\n        ('LGBC', LGBMClassifier(random_state=RS))\n    ])\n]\n\n\nnames = [\n    'DummyClassifier',\n    'XGBClassifier',\n    'RandomForestClassifier',\n    'LGBMClassifier',\n]\n\nshort_names = ['DC', 'XGBC', 'RFC', 'LGBC']\n\nmodels = pd.DataFrame(\n    data={'name': names,\n          'short_name': short_names,\n          'model': pipelines\n    }\n)\nmodels","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:31:56.238002Z","iopub.execute_input":"2023-07-31T10:31:56.238760Z","iopub.status.idle":"2023-07-31T10:31:56.361911Z","shell.execute_reply.started":"2023-07-31T10:31:56.238706Z","shell.execute_reply":"2023-07-31T10:31:56.360388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the model table, we leave only those algorithms that are specified in the ESTIMATOR_LIST list ","metadata":{}},{"cell_type":"code","source":"for item in range(models.shape[0]):\n    if models.loc[item,'name'] not in ESTIMATOR_LIST:\n        models = models.drop(item, axis=0)\n        \nmodels = models.reset_index(drop=True)\n\nmodels","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:01.122216Z","iopub.execute_input":"2023-07-31T10:32:01.122803Z","iopub.status.idle":"2023-07-31T10:32:01.229822Z","shell.execute_reply.started":"2023-07-31T10:32:01.122760Z","shell.execute_reply":"2023-07-31T10:32:01.228444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model selection","metadata":{}},{"cell_type":"code","source":"X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:04.450837Z","iopub.execute_input":"2023-07-31T10:32:04.451351Z","iopub.status.idle":"2023-07-31T10:32:04.463480Z","shell.execute_reply.started":"2023-07-31T10:32:04.451298Z","shell.execute_reply":"2023-07-31T10:32:04.462187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform training and select the best model\nbest_log_loss = float('inf')\nbest_model = None\n\nfor item in range(models.shape[0]):\n    model = models.loc[item, 'model']\n    model.fit(X_train, Y_train)  # Train on scaled data\n\n    Y_pred = model.predict(X_valid)\n    logloss = log_loss(Y_valid, Y_pred)\n\n    if logloss < best_log_loss:\n        best_log_loss = logloss\n        best_model = model\n\nprint(\"The smallest Log Loss of the algorithm:\", best_model.steps[-1][-1])\nprint(\"Lowest Log Loss value:\", best_log_loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:06.560152Z","iopub.execute_input":"2023-07-31T10:32:06.560674Z","iopub.status.idle":"2023-07-31T10:32:12.306015Z","shell.execute_reply.started":"2023-07-31T10:32:06.560633Z","shell.execute_reply":"2023-07-31T10:32:12.304757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The best model is RandomForestClassifier\n\n* Best Log Loss : 2.906","metadata":{}},{"cell_type":"code","source":"best_model","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:16.361362Z","iopub.execute_input":"2023-07-31T10:32:16.361866Z","iopub.status.idle":"2023-07-31T10:32:16.442251Z","shell.execute_reply.started":"2023-07-31T10:32:16.361827Z","shell.execute_reply":"2023-07-31T10:32:16.440984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions = best_model.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:21.151510Z","iopub.execute_input":"2023-07-31T10:32:21.152010Z","iopub.status.idle":"2023-07-31T10:32:21.194050Z","shell.execute_reply.started":"2023-07-31T10:32:21.151971Z","shell.execute_reply":"2023-07-31T10:32:21.192663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:24.303700Z","iopub.execute_input":"2023-07-31T10:32:24.304207Z","iopub.status.idle":"2023-07-31T10:32:24.317987Z","shell.execute_reply.started":"2023-07-31T10:32:24.304167Z","shell.execute_reply":"2023-07-31T10:32:24.316828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION","metadata":{}},{"cell_type":"markdown","source":"My version 1","metadata":{}},{"cell_type":"code","source":"# train_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:14:30.794089Z","iopub.execute_input":"2023-07-31T10:14:30.794762Z","iopub.status.idle":"2023-07-31T10:14:30.801091Z","shell.execute_reply.started":"2023-07-31T10:14:30.794684Z","shell.execute_reply":"2023-07-31T10:14:30.799684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:28.481289Z","iopub.execute_input":"2023-07-31T10:32:28.482297Z","iopub.status.idle":"2023-07-31T10:32:28.499082Z","shell.execute_reply.started":"2023-07-31T10:32:28.482246Z","shell.execute_reply":"2023-07-31T10:32:28.497852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:32.262598Z","iopub.execute_input":"2023-07-31T10:32:32.263224Z","iopub.status.idle":"2023-07-31T10:32:32.286166Z","shell.execute_reply.started":"2023-07-31T10:32:32.263169Z","shell.execute_reply":"2023-07-31T10:32:32.284828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:32:36.811000Z","iopub.execute_input":"2023-07-31T10:32:36.811717Z","iopub.status.idle":"2023-07-31T10:32:36.818502Z","shell.execute_reply.started":"2023-07-31T10:32:36.811670Z","shell.execute_reply":"2023-07-31T10:32:36.817240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for _, model_row in models.iterrows():\n#     model = model_row['model']\n#     X_test_preprocessed = model.named_steps['preproc_tree'].transform(test_data)\n    \n#     predictions = model.named_steps[model_row['short_name']].predict(X_test_preprocessed)\n#     predictions_df[model_row['short_name']] = predictions","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:34:04.235821Z","iopub.execute_input":"2023-07-31T10:34:04.236395Z","iopub.status.idle":"2023-07-31T10:34:04.243743Z","shell.execute_reply.started":"2023-07-31T10:34:04.236352Z","shell.execute_reply":"2023-07-31T10:34:04.242252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_predictions = predictions_df.mean(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_df = pd.DataFrame({\n#     'Id': test_data['Id'],  \n#     'class_0': 1 - final_predictions,  \n#     'class_1': final_predictions  \n# })","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}